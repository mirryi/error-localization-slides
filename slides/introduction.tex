\begin{frame}{Nowadays\ldots}
  \pause
  \begin{itemize}
    \item We program with high-level abstractions \\ \pause
      but these abstractions can be complex!

      \pause
    \item We rely on help from our editors \\ \pause
      which provide \emph{rich semantic services}!

      \pause
    \item We write a lot of ill-formed code \\ \pause
      so services must be \emph{error-resilient}!
  \end{itemize}

  \note[item]{So nowadays, in this, well---I'd say we're now firmly in the middle of the 3rd decade of the
    21st century---we program with high-level abstractions\ldots}
  \note[item]{but these abstractions can be pretty complex, right?}
  \note[item]{As a result, we rely on quite a bit of help from editors and other tooling}
  \note[item]{because they provide these rich semantic services such as code completion or automated
    refactoring}
  \note[item]{Now, the problem is, a lot of our code is ill-formed in some way---in fact, most of
    the time, the code we're writing is hardly complete, so it's probably wrong somehow}
  \note[item]{This means that these services have to be able to handle our bad code, or resilient to errors}
\end{frame}

\begin{frame}{Error localization and recovery}
  As programmers, we want tools that can \\[1em]

  \pause
  \begin{itemize}
    \item describe \emph{what} and \emph{where} the errors are \pause (\emph{localization})

      \pause
    \item and, even when an error is encountered,
      continue on and find other errors \pause (\emph{recovery})
  \end{itemize}

  \vspace{1em}
  \pause
  \textbf{Our focus:} \emph{type} error localization and recovery!

  \note[item]{This is what we're concerned about in this talk---tools that are resilient to
    errors, and in particular that means}
  \note[item]{that they can tell us what the error is and where it is in our code. We call this
    localization}
  \note[item]{and, even in the face of errors, recover optimistically to continue doing what it's
    doing and find other errors, ideally with minimal loss in service---recovery}
  \note[item]{As the title of the talk suggests, we're concerned in particular today about these
    two notions as they pertain to \emph{type} errors}
\end{frame}

\begin{frame}[fragile, t]{Observations in practice}
  \begin{center}
    $%
      \ELet{f}{\ELam{b}{\TBool}{\cdots}}{\pause
        \ELet{x}
          {\EIf{\ETrue}
               {\onderset<9>{\goodcolor{Emerald}{\bm{\wedge}}}{\onderset<7>{\goodcolor{Red}{\bm{\wedge}}}{\ENum{5}}}}
               {\onderset<4-5,6,8,9>{\goodcolor{Red}{\bm{\wedge}}}{\EFalse}}}
          {\pause\EAp{f}{\onderset<5,6>{\goodcolor{Red}{\wedge}}{x}}}
      }
    $%
  \end{center}
  \vspace{-18pt}
  \begin{semiverbatim}\small\only<4-5>{
1 | let x = if true then 5 else false in f x
                                \textcolor{red}{^^^^^}
\textcolor{red}{\textbf{Error}}: This expression has type bool but an expression
         was expected of type int
     \uncover<5>{
1 | let x = if true then 5 else false in f x
                                           \textcolor{red}{^}
\textcolor{red}{\textbf{Error}}: This expression has type int but an expression
         was expected of type bool}}\only<6>{
Main.hs:4:26: \textbf{\textcolor{red}{error}:} \textbf{[\textcolor{red}{GHC-39999}]}
    • Couldn't match expected type ‘Int’ with actual type ‘Bool’
  |
4 | _ = let x = if True then (5::Int) else \textcolor{red}{\textbf{False}} in f x
  |                                        \textcolor{red}{\textbf{^^^^^}}
    • Couldn't match expected type ‘Bool’ with actual type ‘Int’
  |
4 | _ = let x = if True then (5::Int) else False in f \textcolor{red}{\textbf{x}}
  |                                                   \textcolor{red}{\textbf{^}}}\only<7>{
Main.hs:4:26: \textbf{\textcolor{red}{error}:} \textbf{[\textcolor{red}{GHC-39999}]}
    • No instance for ‘Num Bool’ arising from the literal ‘5’
  |
4 | _ = let x = if True then \textcolor{red}{\textbf{5}} else False in f x
  |                          \textcolor{red}{\textbf{^}}}\only<8>{
main.cpp:1:50: \textcolor{red}{\textbf{error:}} inconsistent deduction for auto return type:
                      ‘int’ and then ‘bool’
    1 | auto x() { if (true) { return 5; } else { return \textcolor{red}{\textbf{false}}; } }
      |                                              \textcolor{red}{\textbf{^~~~~}}
    2 | auto y = f(x())}\only<9>{
\textbf{\textcolor{red}{error[E0308]}: `if` and `else` have incompatible types}
 --> src/main.rs:2:30
  |
6 | let x = if true { 5 } else { false }; f(x);
  |                  \textcolor{Emerald}{\textbf{-}}        \textcolor{red}{\textbf{^^^^^ expected integer, found `bool`}}
  |                  \textcolor{Emerald}{\textbf{|}}
  |                  \textcolor{Emerald}{\textbf{expected because of this}}}
  \end{semiverbatim}

  \note[item]<1-3>{Since being able to localize and recover from errors is pretty important, this problem
    has garnered plenty of practical interest, and we can see that production tooling supports some
    form of localization and recovery capability.}
  \note[item]<1-3>{Let's look for example at this program, in which we've a function f that takes a
    boolean---and does something}
  \note[item]<1-3>{x is determined by a conditional}
  \note[item]<1-3>{and f is applied to x}
  \note[item]<1-3>{We can immediately see that the branches of the conditional are mismatched wrt to
    typing, so there should be some support of error diagnostic}
  \note[item]<4->{and in fact if we throw this at the OCaml compiler, it says, yes, there is, and it's
    on the false, having prioritized the first branch's integer}
  \note[item]<4->{ocamlc will stop here, but merlin, which powers editor services nowadays, will also
    say that there's another error on the usage of x, since it's determined x to be an int but f takes
    a bool}
  \note[item]<4->{OK, that's all well and good, so what about Haskell?}
  \note[item]<4->{It's in agreement with merlin here, though actually if we removed the explicit Int
    annotation it would blame 5 for not being an instance of Num Bool}
  \note[item]<4->{For C++ I've had to mangle the program a little but the idea is the same, and g++ is
    also on the false but suggests more generally that we should look at earlier return statements
    as well}
  \note[item]<4->{Rust does similarly, but actually also marks part of the error on 5}
\end{frame}

\begin{frame}
  Today's tooling is error-resilient to a certain degree\pause, but

  \vspace{1em}
  \pause
  \begin{itemize}
    \item localization can be varied\pause, often guessing about \emph{user intent}

      \pause
    \item recovery necessitates reasoning without complete knowledge about types

      \pause
    \item decisions can influence other downstream decisions
  \end{itemize}

  \note[item]{Now obviously these languages all have different kinds of type systems, but from this
    informal exercise we can observe that}
  \note[item]{decisions about how to localize can vary, and often tools will try to guess users'
    intentions when where to localize errors to}
  \note[item]{Then, to recover, they have to somehow operate with incomplete knowledge about the
    types at play}
  \note[item]{and together, upstream error localization decisions, once recovered from, can
    influence downstream decisions}
  \note[item]{We think, therefore, that this subject would benefit from rigorous treatment.
    Unfortunately, in theory\ldots}
\end{frame}

\begin{frame}{\ldots\ in theory}
  \begin{center}
    \Large
    $\Gamma \vdash e : \tau$
  \end{center}

  \note[item]{In theory, our type systems generally look like some variation of this}
  \note[item]{that is, they give rules for when terms are well-typed}
\end{frame}

\begin{frame}{A definitional gap problem}
  \begin{center}
    Most of the code we write is \emph{ill-formed}\pause,
    but conventional language definitions
    \emph{only specify the behaviour of well-formed programs}.
  \end{center}
  \pause
  \[%
    \bm{\Downarrow}
  \]%

  \begin{center}
    If a type error appears \textcolor{RedOrange}{\textbf{anywhere}},\\
    the program is meaningless \textcolor{Red}{\textbf{everywhere}}.
  \end{center}

  \note[item]{Unfortunately, most of the code we write isn't well-formed in this way, but ill-formed}
  \note[item]{but our conventional language definitions only give semantics for well-formed programs}
  \note[item]{So if a type error appears anywhere}
  \note[item]{as far as the specifications are concerned, the program becomes meaningless as a whole}
\end{frame}

\begin{frame}{The goal}
  We'd like a way to \emph{formally} specify type checkers that are capable of localizing and
  recovering from errors

  \vspace{1em}
  \pause
  \begin{emphbox}{Guiding principle\uncover<4->{ (totality)}}
    \pause
    These typing semantics should describe \\
    \emph{all syntactically well-formed programs}.
  \end{emphbox}

  \note[item]{We'd like a way to alleviate this, by being able to create precise specifications for
    the semantics of these ill-typed programs}
  \note[item]{in particular, formal specifications for how to handle type errors and recover in
    spite of them}
  \note[item]{And these type checker semantics should describe all syntactically well-formed
    programs}
  \note[item]{This notion we'll call totality}
\end{frame}

\begin{frame}{This paper is about\ldots}
  \begin{itemize}
    \item<1-> the \textbf{marked lambda calculus}%
      \uncover<2->{%
        : a judgmental framework for \onderline<3->{total} \onderline<4->{bidirectional}
        type error localization and recovery%
      }

    \item<5-> \textbf{type hole inference}%
      \uncover<6->{%
        : a global, constraint-based system \\
        \uncover<7->{
          that is \emph{gradual} and \emph{neutral} in error localization and recovery
        }
      }
  \end{itemize}

  \note[item]{So this paper is about, first of all, the marked lambda calculus}
  \note[item]{a judgmental framework for doing these things in a bidirectional fashion}
  \note[item]{The emphasis is on total, and}
  \note[item]{we choose bidirectional systems as our starting point because it creates a flow of
  typing data that is conducive to intuitive error localization}
  \note[item]{Then, we'll describe how to layer type hole inference, a global constraint-based
    inference system atop the marked lambda calculus in a way that allows us to neatly combine the
    bidirectional and unification approaches for even better localization}
\end{frame}
